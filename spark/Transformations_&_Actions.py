# Databricks notebook source
# MAGIC %md
# MAGIC ## Transformations & Actions no Spark
# MAGIC  - Catalyst Optimizer
# MAGIC  - DAGScheduler

# COMMAND ----------

# MAGIC %md
# MAGIC ### Transformations
# MAGIC S√£o opera√ß√µes declarativas que crieam um novo RDD/DataFrame, mas n√£o s√£o executadas at√© que uma action entre em cena.
# MAGIC
# MAGIC - **Exemplos:**
# MAGIC
# MAGIC   - ``map()``
# MAGIC
# MAGIC   - ``filter()``
# MAGIC
# MAGIC   - ``select()``
# MAGIC
# MAGIC   - ``withColumn()``
# MAGIC
# MAGIC   - ``join()``
# MAGIC
# MAGIC   - ``groupBy()``
# MAGIC
# MAGIC   - ``distinct()``
# MAGIC
# MAGIC S√£o chamadas de 'Lazy', em resumo o Spark constroi apenas um plano logico, mas n√£o o executa. Esse plano precisa ser avaliado.
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC ### Action
# MAGIC S√£o opera√ß√µes que disparam a execu√ß√£o real do plano l√≥gico criado pelas transformations. As a√ß√µes retornam um valor para o driver ou gravam dados em uma sa√≠da externa.inicia os stages e tarefas no cluster.
# MAGIC
# MAGIC - **Exemplos:**
# MAGIC
# MAGIC   - ``count()``
# MAGIC
# MAGIC   - ``collect()``
# MAGIC
# MAGIC   - ``show()``
# MAGIC
# MAGIC   - ``write()``
# MAGIC
# MAGIC   - ``take``
# MAGIC
# MAGIC Action: o Spark executa o job

# COMMAND ----------

# MAGIC %sql
# MAGIC --- Criar Volume Gerenciado em dev
# MAGIC CREATE VOLUME dev.bronze.flat_files
# MAGIC

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, StringType, DoubleType, BooleanType, TimestampType

file_path ='/Volumes/dev/bronze/flat_files/orders.csv'

schema = StructType([
    StructField("event_id", StringType(), False),
    StructField("user_id", StringType(), False),
    StructField("order_id", StringType(), False),
    StructField("product_id", StringType(), False),
    StructField("event_type", StringType(), False),
    StructField("price", DoubleType(), True),
    StructField("region", StringType(), True),
    StructField("event_timestamp", TimestampType(), True),
    StructField("is_delayed", BooleanType(), True),
    StructField("is_returned", BooleanType(), True)
])

orders_df = spark.read.schema(schema).csv(file_path, header=True, inferSchema=False)

# COMMAND ----------

orders_df.display()

# COMMAND ----------

resul_df = (
    orders_df
    .filter(orders_df.region == 'SP')
    .groupBy("event_type", "is_returned")
    .agg({"price": "avg"})
    .orderBy("avg(price)", ascending=False)
    .limit(10)
)

# COMMAND ----------

resul_df.explain(True)

# COMMAND ----------

# MAGIC %md
# MAGIC ### Catalyst Optimizer
# MAGIC
# MAGIC - Otimiza√ß√£o do Plano de Execu√ß√£o
# MAGIC
# MAGIC - Ajuste Fino de Consultas
# MAGIC   - classificando as opera√ß√µes em transforma√ß√µes estreitas (narrow) e largas (wide). Essa orquestra√ß√£o inteligente contribui significativamente para o desempenho do Spark
# MAGIC
# MAGIC - Predicate Pushdown
# MAGIC   - Em vez de ler todos os dados e depois filtr√°-los na mem√≥ria, o Catalyst move o filtro para mais perto da fonte de dados
# MAGIC   
# MAGIC - Sele√ß√£o do Plano Mais Eficiente
# MAGIC   - Em certos cen√°rios, o Spark pode gerar m√∫ltiplos planos f√≠sicos com base nas estrat√©gias de execu√ß√£o propostas pelo Catalyst. Nesses casos, o Modelo de Custo do Spark seleciona o plano mais eficient   

# COMMAND ----------

resul_df = (
    orders_df
    .filter(orders_df.region == 'SP') # Transformation 1
    .groupBy("event_type", "is_returned") # Transformation 2
    .agg({"price": "avg"}) # Transformation 3
    .orderBy("avg(price)", ascending=False) # Transformation 4 
)

resul_df.show() # Action

#Physical Plan (execut√°vel no cluster com Photon) em alto nivel
FileScan CSV [event_type, price, region, is_returned]
  ‚îî‚îÄ PhotonFilter: region IS NOT NULL AND region = 'SP'
     ‚îî‚îÄ PhotonProject: event_type, price, is_returned
        ‚îî‚îÄ PhotonGroupingAgg (partial): avg(price) BY event_type, is_returned
           ‚îî‚îÄ Shuffle (hash partitioning by event_type, is_returned)
              ‚îî‚îÄ PhotonGroupingAgg (final): avg(price)
                 ‚îî‚îÄ Shuffle (range partitioning by avg(price) DESC)
                    ‚îî‚îÄ PhotonSort: avg(price) DESC NULLS LAST
                       ‚îî‚îÄ ColumnarToRow
                          ‚îî‚îÄ Output: event_type, is_returned, avg(price)

# COMMAND ----------

# MAGIC %md
# MAGIC ## DAGScheduler 
# MAGIC  - ### Gerencia a execu√ß√£o de est√°gios, depend√™ncias e tratamento de falhas em um cluster Spark
# MAGIC  - O DAGScheduler √© uma camada central de agendamento do Apache Spark, rodando exclusivamente no driver
# MAGIC  - O DAGScheduler √© fundamental para a toler√¢ncia a falhas do Spark, especialmente no contexto de shuffles.
# MAGIC  
# MAGIC  **Responsabilidades:**
# MAGIC  - Computar um Grafo Ac√≠clico Dirigido (DAG) de execu√ß√£o (DAG de est√°gios) para cada job.
# MAGIC  - Determinar as localiza√ß√µes preferenciais para a execu√ß√£o de cada tarefa. (o Spark minimiza a movimenta√ß√£o de dados pela rede ao executar uma tarefa no mesmo n√≥ onde os dados necess√°rios j√° residem)
# MAGIC  - Gerenciar falhas devido √† perda de arquivos de sa√≠da de shuffle.

# COMMAND ----------

## √Årvore do Plano F√≠sico - DAG Stages
Stage 1: Leitura e pr√©-processamento
  - FileScan CSV
  - PhotonFilter
  - PhotonProject
  - PhotonGroupingAgg (partial)
  - ‚Üí shuffle: hash partitioning by (event_type, is_returned)

Stage 2: Agrega√ß√£o final
  - PhotonGroupingAgg (final)
  - ‚Üí shuffle: range partitioning by avg(price)

Stage 3: Ordena√ß√£o final + coleta
  - PhotonSort: avg(price) DESC
  - ColumnarToRow (prepara para exibir .show())
  - Output: envia resultado ao driver


# COMMAND ----------

# MAGIC %md
# MAGIC ### Resumo do fluxo de execu√ß√£o
# MAGIC Transformations criam um plano l√≥gico (lazy).
# MAGIC
# MAGIC Action dispara o job.
# MAGIC
# MAGIC Catalyst optimizer gera o physical plan, construindo o DAG.
# MAGIC
# MAGIC DAGScheduler quebra o DAG em stages (com base em shuffles).
# MAGIC
# MAGIC Cada stage √© dividido em v√°rias tasks (uma por partition).
# MAGIC
# MAGIC TaskScheduler envia as tasks aos executors nos workers.
# MAGIC
# MAGIC Os executors rodam as tasks e enviam resultados ao driver.
# MAGIC
# MAGIC Se for um ResultStage, o driver recebe o resultado da action. <br>
# MAGIC
# MAGIC
# MAGIC ```sh
# MAGIC [ Transformations (lazy) ]
# MAGIC             ‚Üì
# MAGIC        [ Action ]
# MAGIC             ‚Üì
# MAGIC     Catalyst Optimizer
# MAGIC             ‚Üì
# MAGIC        Logical Plan
# MAGIC             ‚Üì
# MAGIC        Physical Plan
# MAGIC             ‚Üì
# MAGIC         DAG of stages
# MAGIC             ‚Üì
# MAGIC       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
# MAGIC       ‚îÇ Stage 1    ‚îÇ ‚Äî> tasks (partitions)
# MAGIC       ‚îÇ Stage 2    ‚îÇ ‚Äî> tasks
# MAGIC       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# MAGIC             ‚Üì
# MAGIC       Executors run tasks
# MAGIC             ‚Üì
# MAGIC       Resultado no driver
# MAGIC
# MAGIC ```

# COMMAND ----------

# MAGIC %md
# MAGIC ### Conceitos e Propriedades:
# MAGIC
# MAGIC  - Transforma√ß√µes Narrow: Opera√ß√µes RDD (como map, filter) onde cada parti√ß√£o da RDD pai contribui com no m√°ximo uma parti√ß√£o para a RDD filha. N√£o requerem embaralhamento de dados.
# MAGIC
# MAGIC  - Transforma√ß√µes Wide: Opera√ß√µes RDD (como groupByKey, join, reduceByKey) onde cada parti√ß√£o da RDD pai pode contribuir com m√∫ltiplas parti√ß√µes para a RDD filha. Exigem embaralhamento de dados (shuffle), que √© uma opera√ß√£o cara.
# MAGIC
# MAGIC - ShuffleDependency: Uma depend√™ncia entre RDDs que indica uma transforma√ß√£o wide e requer embaralhamento de dados.
# MAGIC
# MAGIC - ResultStage: O est√°gio final de um Job, que cont√©m ResultTasks que computam e retornam o resultado final ao Driver.
# MAGIC
# MAGIC - ShuffleMapStage: Um est√°gio que produz sa√≠das de embaralhamento (map outputs) que ser√£o consumidas por um est√°gio subsequente (normalmente um est√°gio Result ou outro est√°gio ShuffleMap).
# MAGIC
# MAGIC - TaskSet: Um conjunto de tarefas de um √∫nico est√°gio que o TaskScheduler submete para execu√ß√£o.
# MAGIC
# MAGIC - ActiveJob: Uma representa√ß√£o interna de um job ativo no DAGScheduler, mantendo informa√ß√µes como o jobId, a callSite, o JobListener e as propriedades de agendamento.
# MAGIC
# MAGIC - BarrierJobSlotsNumberCheckFailed: Uma exce√ß√£o lan√ßada quando um est√°gio de barreira (barrier stage) requer um n√∫mero espec√≠fico de slots de tarefa, mas os recursos dispon√≠veis s√£o insuficientes.
# MAGIC
# MAGIC - AccumulatorV2: A API para acumuladores no Spark, que permite que as tarefas construam valores de forma eficiente fora da execu√ß√£o do DAG, como contadores ou somas.

# COMMAND ----------

# MAGIC %md
# MAGIC ## üìö Refer√™ncias oficiais
# MAGIC
# MAGIC üìÑ Stages and Tasks (Performance Tuning): https://spark.apache.org/docs/latest/tuning.html#level-of-parallelism
# MAGIC
# MAGIC üìÑ Spark DataFrame API Docs: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html
# MAGIC
# MAGIC Stages: https://books.japila.pl/apache-spark-internals/scheduler/DAGScheduler/
